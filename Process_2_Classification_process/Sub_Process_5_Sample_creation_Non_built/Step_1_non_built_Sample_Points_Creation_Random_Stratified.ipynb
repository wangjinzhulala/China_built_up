{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of non-built control points\n",
    "num_non_built = 5500\n",
    "\n",
    "# define the data for NDVI creationg\n",
    "Date = ee.DateRange('2017-01-01','2019-12-31')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the NDVI img\n",
    "NDVI = ee.ImageCollection(\"MODIS/006/MOD13Q1\")\\\n",
    "         .filterDate(Date)\\\n",
    "         .select(\"NDVI\")\\\n",
    "         .median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the region to analysis\n",
    "region    = ['华东','东北','中南','华北','西北','西南']\n",
    "region_en = ['huadong','dongbei','zhongnan','huabei','xibei','xinan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the sample_point_num for each NDVI value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step_1: Compute the histogram of NDVI for each Landsat image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI hist computation of huadong completed!\n",
      "NDVI hist computation of dongbei completed!\n",
      "NDVI hist computation of zhongnan completed!\n",
      "NDVI hist computation of huabei completed!\n",
      "NDVI hist computation of xibei completed!\n",
      "NDVI hist computation of xinan completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,names in enumerate(zip(region,region_en)):\n",
    "    \n",
    "    # unpack parameters\n",
    "    name_cn = names[0]\n",
    "    name_en = names[1]\n",
    "    \n",
    "    # import some spatial constrains\n",
    "    Target_area = ee.FeatureCollection(\"users/wangjinzhulala/China_built_up/01_Boundary_shp/China_zone\")\\\n",
    "                    .filterMetadata('NAME1','equals',name_cn)\n",
    "    \n",
    "        \n",
    "    # ____________________Step_1:Calculate the area percentage of each NDVI value____________________________\n",
    "    \n",
    "    NDVI_frequency = NDVI.reduceRegion(reducer   = ee.Reducer.histogram(200),\n",
    "                                       geometry  = Target_area.geometry(), \n",
    "                                       scale     = 500, \n",
    "                                       maxPixels = int(1e13)).getInfo()\n",
    "\n",
    "    # _______________________________Step_2:unpack the value from histogram_________________________________\n",
    "    \n",
    "    count    = [round(i) for i in NDVI_frequency['NDVI']['histogram']]\n",
    "    nd_value = [round(i) for i in NDVI_frequency['NDVI']['bucketMeans']]  \n",
    "    \n",
    "    # store the ndvi histogram to a datafram, \n",
    "    # NOTE here we divide ndvi by 100 to ensure that the actual NDVI level is at the 0.01 scale\n",
    "    NDVI_hist_df = pd.DataFrame({'NDVI':[int(i/100) for i in nd_value],'Freq':count})\n",
    "\n",
    "    # calculate how many points we shold collect at each ndvi level\n",
    "    NDVI_hist_df['Select_num'] = NDVI_hist_df['Freq'].apply(lambda x: round(x/NDVI_hist_df['Freq'].sum() * num_non_built))\n",
    "\n",
    "    # _______________________________Step_3:save the NDVI_hist_df to local disk_________________________________\n",
    "    NDVI_hist_df.to_csv(f'./Result_df/NDVI_area_propotion_{i+1}_{name_en}.csv',index=False)\n",
    "\n",
    "    # print out the process\n",
    "    print(f'NDVI hist computation of {name_en} completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step_2: Create 10K random sample point and extract NDVI value to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI random points of huadong are exported!\n",
      "NDVI random points of dongbei are exported!\n",
      "NDVI random points of zhongnan are exported!\n",
      "NDVI random points of huabei are exported!\n",
      "NDVI random points of xibei are exported!\n",
      "NDVI random points of xinan are exported!\n"
     ]
    }
   ],
   "source": [
    "for i,names in enumerate(zip(region,region_en)):\n",
    "    \n",
    "    # unpack parameters\n",
    "    name_cn = names[0]\n",
    "    name_en = names[1]\n",
    "    \n",
    "    export_name = f'NDVI random {name_en}'\n",
    "    \n",
    "    # import target area\n",
    "    Target_area = ee.FeatureCollection(\"users/wangjinzhulala/China_built_up/01_Boundary_shp/China_zone\")\\\n",
    "                    .filterMetadata('NAME1','equals',name_cn)\n",
    "    \n",
    "\n",
    "    # create 50K random sample points\n",
    "    Random_pt_ndvi = NDVI.sample(region     = Target_area,\n",
    "                                 scale      = 250,\n",
    "                                 numPixels  = 50000,\n",
    "                                 geometries = True)\n",
    "\n",
    "    # export the sample points to GEE asset, because on-the-fly computation required a lot of time and memeory\n",
    "    # we can impot the result later for better efficienty\n",
    "\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "                            collection  = Random_pt_ndvi,\n",
    "                            description = export_name,\n",
    "                            assetId     = f'users/wangjinzhulala/China_built_up/02_control_sample/01_Random_pt_ndvi_0{i+1}_{name_en}')\n",
    "    task.start()\n",
    "    \n",
    "    # print out the process\n",
    "    print(f'NDVI random points of {name_en} are exported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step_3_Random select sample from the 50K points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for ramdom sampling\n",
    "\n",
    "def sample_list(x):\n",
    "    \n",
    "    L = x['.geo']\n",
    "    n = int(x['Select_num'])\n",
    "    \n",
    "    select = random.sample(L,n)\n",
    "    \n",
    "    return select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_list = []\n",
    "\n",
    "for i,names in enumerate(zip(region,region_en)):\n",
    "    \n",
    "    # unpack parameters\n",
    "    name_cn = names[0]\n",
    "    name_en = names[1]\n",
    "\n",
    "    #________________________Step_1: Preprocessing for 50K sample_______________________\n",
    "\n",
    "    # read the random points\n",
    "    random_df = pd.read_csv(f'./Random_pt/Random_pt_ndvi_0{i+1}_{name_en}.csv')\n",
    "\n",
    "    # convert the NDVI to integers, here divide by 100 to ensure a 0.01 scale \n",
    "    # in actual NDVI scale\n",
    "    random_df['NDVI'] = random_df['NDVI'].apply(lambda x: int(x/100))\n",
    "\n",
    "    # transform .geo to json\n",
    "    random_df.drop('system:index',1,inplace=True)\n",
    "    random_df['.geo'] = random_df['.geo'].apply(lambda x: json.loads(x))\n",
    "\n",
    "    # collapse all json points with the same NDVI value into one list\n",
    "    # and store in the df_50K dataframe\n",
    "    df_50K = pd.DataFrame(random_df.groupby('NDVI')['.geo'].apply(lambda x: list(x)))\n",
    "    \n",
    "\n",
    "\n",
    "    #_________________________Step_2: Join df_histgrame with df_50K______________________\n",
    "\n",
    "    # Select the df_hist that are in the same year with df_50K\n",
    "    df_hist = pd.read_csv(f'./Result_df/NDVI_area_propotion_{i+1}_{name_en}.csv')\n",
    "\n",
    "    # Join df_hist and df_50K, remove the rows with a 0 select_num\n",
    "    df_join = df_hist.join(df_50K, on='NDVI',how='inner')\n",
    "    df_join = df_join[df_join['Select_num'] > 0]\n",
    "\n",
    "\n",
    "\n",
    "    #_________________________Step_3: Perform the random sampling\n",
    "\n",
    "    # Apply the function to collapse all json points of the same nd value into one list\n",
    "    df_join['Sample'] = df_join.apply(sample_list,1)\n",
    "\n",
    "    # Extract only necessay data\n",
    "    df_join_sample = df_join[['NDVI','Sample']]\n",
    "\n",
    "    # Explode the sample column, so we get the random point at each row\n",
    "    df_join_sample = df_join_sample.explode('Sample')\n",
    "    \n",
    "    # add the region name to df\n",
    "    df_join_sample['region'] = name_en\n",
    "    \n",
    "    # add the sample_df to list\n",
    "    sample_df_list.append(df_join_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concat all random-stratified sample into one datafram\n",
    "# sample_df = pd.concat(sample_df_list).reset_index(drop=True)\n",
    "\n",
    "# # unravel the sample to get lon/lat\n",
    "# sample_df['lon'] = sample_df['Sample'].apply(lambda x: x['coordinates'][0])\n",
    "# sample_df['lat'] = sample_df['Sample'].apply(lambda x: x['coordinates'][1])\n",
    "# sample_df.drop('Sample',1,inplace=True)\n",
    "\n",
    "# # Save the sample_df to disk\n",
    "# sample_df.to_csv('./Result_df/Sample_point.csv',index=False)\n",
    "\n",
    "# Load the sample_df\n",
    "sample_df = pd.read_csv('./Result_df/Sample_point.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI</th>\n",
       "      <th>region</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14</td>\n",
       "      <td>huadong</td>\n",
       "      <td>117.825121</td>\n",
       "      <td>38.230031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13</td>\n",
       "      <td>huadong</td>\n",
       "      <td>118.862632</td>\n",
       "      <td>37.992384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>huadong</td>\n",
       "      <td>118.254436</td>\n",
       "      <td>38.035157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12</td>\n",
       "      <td>huadong</td>\n",
       "      <td>118.154338</td>\n",
       "      <td>37.905279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12</td>\n",
       "      <td>huadong</td>\n",
       "      <td>118.804646</td>\n",
       "      <td>37.232732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32994</th>\n",
       "      <td>87</td>\n",
       "      <td>xinan</td>\n",
       "      <td>95.025083</td>\n",
       "      <td>29.144323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>87</td>\n",
       "      <td>xinan</td>\n",
       "      <td>94.751412</td>\n",
       "      <td>27.920226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>87</td>\n",
       "      <td>xinan</td>\n",
       "      <td>95.747002</td>\n",
       "      <td>28.551668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>88</td>\n",
       "      <td>xinan</td>\n",
       "      <td>95.944912</td>\n",
       "      <td>28.373304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>89</td>\n",
       "      <td>xinan</td>\n",
       "      <td>95.260748</td>\n",
       "      <td>28.468856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NDVI   region         lon        lat\n",
       "0       -14  huadong  117.825121  38.230031\n",
       "1       -13  huadong  118.862632  37.992384\n",
       "2       -13  huadong  118.254436  38.035157\n",
       "3       -12  huadong  118.154338  37.905279\n",
       "4       -12  huadong  118.804646  37.232732\n",
       "...     ...      ...         ...        ...\n",
       "32994    87    xinan   95.025083  29.144323\n",
       "32995    87    xinan   94.751412  27.920226\n",
       "32996    87    xinan   95.747002  28.551668\n",
       "32997    88    xinan   95.944912  28.373304\n",
       "32998    89    xinan   95.260748  28.468856\n",
       "\n",
       "[32999 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
